{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "from collections import Counter, OrderedDict\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from nltk.tokenize import word_tokenize\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.environ['KERAS_BACKEND'] = 'theano'\n",
    "os.environ['THEANO_FLAGS'] = 'floatX=float32,device=cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from IPython.display import display\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read image file_name and their captions\n",
    "file_name_caption = pickle.load(open( \"file_name_caption.bat\", \"rb\" ))\n",
    "# Read image file_name and their VGG 16 weights\n",
    "file_name_images = pickle.load(open( \"file_name_images.bat\", \"rb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "keras_model = 'keras_image_caption_model.dat'\n",
    "train_dir = '/home/qhduan/Downloads/imagedata/train2014'\n",
    "val_dir = '/home/qhduan/Downloads/imagedata/val2014'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = load_model(keras_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "argument = pickle.load(open('argument.dat', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_index = argument['word_index']\n",
    "index_word = argument['index_word']\n",
    "max_len = argument['max_len']\n",
    "START = argument['START']\n",
    "END = argument['END']\n",
    "UNK = argument['UNK']\n",
    "PAD = argument['PAD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sent_to_index(input_sent, word_index, max_len):\n",
    "    padding_size = max_len - len(input_sent)\n",
    "\n",
    "    input_sent = input_sent + padding_size * [PAD]\n",
    "    input_sent_index = []\n",
    "    for w in input_sent:\n",
    "        if w in word_index:\n",
    "            input_sent_index.append(word_index[w])\n",
    "        else:\n",
    "            input_sent_index.append(word_index[UNK])\n",
    "    return input_sent_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_weights(weights, word_index, index_word, max_len):\n",
    "    sent = [START]\n",
    "    while True:\n",
    "        sent_index = sent_to_index(sent, word_index, max_len)\n",
    "        index = model.predict([np.asarray([weights]), np.asarray([sent_index])]).argmax()\n",
    "        if index in index_word:\n",
    "            word = index_word[index]\n",
    "        else:\n",
    "            word = UNK\n",
    "        sent.append(word)\n",
    "        if word == END or len(sent) > max_len:\n",
    "            break\n",
    "    return sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_name_images = sorted(list(file_name_images.items()), key=lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/123050 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|          | 1/123050 [00:00<25:48:14,  1.32it/s]\u001b[A\n",
      "  0%|          | 2/123050 [00:01<25:30:38,  1.34it/s]\u001b[A\n",
      "  0%|          | 3/123050 [00:02<25:56:21,  1.32it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-6:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/threading.py\", line 914, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/qhduan/.local/lib/python3.5/site-packages/tqdm/_tqdm.py\", line 102, in run\n",
      "    for instance in self.tqdm_cls._instances:\n",
      "  File \"/usr/lib/python3.5/_weakrefset.py\", line 60, in __iter__\n",
      "    for itemref in self.data:\n",
      "RuntimeError: Set changed size during iteration\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1%|          | 999/123050 [12:03<24:27:09,  1.39it/s]\n"
     ]
    }
   ],
   "source": [
    "train_bleu = []\n",
    "for file_name, weights in tqdm(file_name_images, file=sys.stdout):\n",
    "    if 'train' not in file_name:\n",
    "        continue\n",
    "    ret = predict_weights(weights, word_index, index_word, max_len)\n",
    "    while ret[0] == START:\n",
    "        ret = ret[1:]\n",
    "    while ret[-1] == END:\n",
    "        ret = ret[:-1]\n",
    "    true = word_tokenize(file_name_caption[file_name])\n",
    "    predict = ret\n",
    "    b = sentence_bleu([true], predict, weights=(1.0,))\n",
    "    train_bleu.append(b)\n",
    "    if len(train_bleu) >= 1000:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 83611/123050 [12:37<7:50:26,  1.40it/s]  "
     ]
    }
   ],
   "source": [
    "test_bleu = []\n",
    "for file_name, weights in tqdm(file_name_images, file=sys.stdout):\n",
    "    if 'val' not in file_name:\n",
    "        continue\n",
    "    ret = predict_weights(weights, word_index, index_word, max_len)\n",
    "    while ret[0] == START:\n",
    "        ret = ret[1:]\n",
    "    while ret[-1] == END:\n",
    "        ret = ret[:-1]\n",
    "    true = word_tokenize(file_name_caption[file_name])\n",
    "    predict = ret\n",
    "    b = sentence_bleu([true], predict, weights=(1.0,))\n",
    "    test_bleu.append(b)\n",
    "    if len(test_bleu) >= 1000:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.30985391884751368"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(train_bleu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.306036089425132"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(test_bleu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
